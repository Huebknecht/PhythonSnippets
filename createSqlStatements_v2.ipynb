{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70161d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading congig file : /Users/e5527h6/Documents/Programming/python/Entwicklungsdaten/config/dataStructure.dic\n",
      "\n",
      "Sheet README will not be processed!\n",
      "Sheet CreateTestData will not be processed!\n",
      "Processing sheet XVA_QTF.\n",
      "---dbo.XVA_QANTIFI_ACT---\n",
      "Processing sheet TR.\n",
      "---mxg.V_TRADES_DLV---\n",
      "Processing sheet TR_T-1.\n",
      "---mxg.V_TRADES_DLV---\n",
      "Processing sheet GE.\n",
      "---zds.V_GESCH_DLV---\n",
      "Processing sheet HM.\n",
      "---focus.V_HEDGE_MEMBERS_DLV---\n",
      "Processing sheet HM_T-1.\n",
      "---focus.V_HEDGE_MEMBERS_DLV---\n",
      "Processing sheet HR.\n",
      "---focus.V_HEDGE_RELATIONSHIPS_DLV---\n",
      "Processing sheet HR_T-1.\n",
      "---focus.V_HEDGE_RELATIONSHIPS_DLV---\n",
      "Processing sheet HMR.\n",
      "---focus.V_HEDGE_MEMBER_RESULTS_DLV---\n",
      "Processing sheet HMR_T-1.\n",
      "---focus.V_HEDGE_MEMBER_RESULTS_DLV---\n",
      "Processing sheet HETS.\n",
      "---focus.V_HEDGE_EFFECTIVENESS_TEST_SETTINGS_DLV---\n",
      "Processing sheet HETS_T-1.\n",
      "---focus.V_HEDGE_EFFECTIVENESS_TEST_SETTINGS_DLV---\n",
      "Processing sheet AHMR.\n",
      "---focus.V_ANALYSIS_A_HEDGE_MEMBER_RESULTS_DLV---\n",
      "Processing sheet RARA.\n",
      "---focus.V_REGRESSION_ANALYSIS_RESULTS_ARCHIVE_DLV---\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# createSqlStatements.ipynb\n",
    "# erzeugt die SQL Insert Statements für die Entwicklungsumgebung\n",
    "#\n",
    " \n",
    "import ast\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    " \n",
    "def readConfigFile(configFile):\n",
    " \n",
    "    print(\"Reading congig file : %s\\n\" % (configFile))\n",
    "    fieldExceptionDic = {}\n",
    "    fileFieldExceptionDic = open(configFile, \"r\", encoding=\"utf8\", errors='ignore')\n",
    "    contents = fileFieldExceptionDic.read()\n",
    "    fieldExceptionDic = ast.literal_eval(contents)\n",
    "    fileFieldExceptionDic.close()\n",
    "    return fieldExceptionDic\n",
    " \n",
    "thisDate = datetime.now().strftime('%Y-%m-%d')\n",
    "timeStamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    " \n",
    "fileDir = \"/Users/e5527h6/Documents/Programming/python/Entwicklungsdaten\"\n",
    "configFile = os.path.join(fileDir, \"config\", \"dataStructure.dic\")\n",
    "inFileName = \"Entwicklungsdaten_SQL_3.4.xlsx\"\n",
    "inFilePath = os.path.join(fileDir, inFileName)\n",
    "try: \n",
    "    excelFile = pd.ExcelFile(inFilePath, engine='openpyxl')\n",
    "except:\n",
    "    print(\"File %s does not exist!\" % (inFilePath))\n",
    "    exit()\n",
    " \n",
    "#  Hash-Tabelle für die HM_ABST; Keys sind die Blattnamen\n",
    "sheetDic = {\"INT_CTP\"   : \"IC\",\n",
    "            \"XVA_QTF\"   : \"XVA\",\n",
    "            \"TR\"        : \"mxg.TRADES\",\n",
    "            \"TR_T-1\"    : \"mxg.TRADES\",\n",
    "            \"GE\"        : \"zds.V_GESCH\",\n",
    "            \"HM\"        : \"focus.HEDGE_MEMBERS\",\n",
    "            \"HM_T-1\"    : \"focus.HEDGE_MEMBERS\",\n",
    "            \"HR\"        : \"focus.HEDGE_RELATIONSHIPS\",\n",
    "            \"HR_T-1\"    : \"focus.HEDGE_RELATIONSHIPS\",\n",
    "            \"HMR\"       : \"focus.HEDGE_MEMBER_RESULTS\",\n",
    "            \"HMR_T-1\"   : \"focus.HEDGE_MEMBER_RESULTS\",\n",
    "            \"HETS\"      : \"focus.HEDGE_EFFECTIVENESS_TEST_SETTINGS\",\n",
    "            \"HETS_T-1\"  : \"focus.HEDGE_EFFECTIVENESS_TEST_SETTINGS\",\n",
    "            \"AHMR\"      : \"focus.ANALYSIS_A_HEDGE_MEMBER_RESULTS\",\n",
    "            \"RARA\"      : \"focus.REGRESSION_ANALYSIS_RESULTS_ARCHIVE\"\n",
    "           }\n",
    " \n",
    "# Datei mit Felddefinitionen einlesen\n",
    "fieldExceptionDic = readConfigFile(configFile)\n",
    " \n",
    "cellCounterFile = 0\n",
    "for sheet in excelFile.sheet_names:\n",
    "    try:\n",
    "        df = pd.read_excel(excelFile, sheet, header=None)\n",
    "    except Exception:\n",
    "        print(\"Fields sheet %s does not exist in file %s\" % (sheet, inFilePath))\n",
    "        continue\n",
    "    if sheet in sheetDic.keys():\n",
    "        sheetName = sheetDic[sheet]\n",
    "        print(\"Processing sheet %s.\" % sheet)\n",
    "    else:\n",
    "        print(\"Sheet %s will not be processed!\" % sheet)\n",
    "        continue\n",
    "    # get PER_DATE_POSITION\n",
    "    perDatePosition = str(df.iat[2, 0])[:10]\n",
    "    # output file\n",
    "    if not os.path.exists(os.path.join(fileDir, 'SQL_Upload')):\n",
    "        os.makedirs(os.path.join(fileDir, 'SQL_Upload'))\n",
    "    outFilePath = os.path.join(fileDir, 'SQL_Upload', 'SQL_Upload_' + sheetName + '#' + perDatePosition + '_cr_' + thisDate + '.sql')\n",
    "    outFileHandle = open(outFilePath,'w')\n",
    "    cellCounterSheet = 0\n",
    "    headerList = []\n",
    "    headerStr = ''\n",
    "    viewNameStage = ''\n",
    "    viewNameQuery = ''\n",
    "    for index, row in df.iterrows():\n",
    "        # extract table name\n",
    "        if index == 0:\n",
    "            viewNameStage = df.iat[index, 0]\n",
    "            viewNameQuery = viewNameStage[:-4]\n",
    "            perDatePosition = df.iat[index + 2, 0].date()\n",
    "        # extract header fields\n",
    "        if index == 1:\n",
    "            headerIdx = 0\n",
    "            for headerField in row:\n",
    "                headerList.append(str(headerField))\n",
    "                headerIdx += 1\n",
    "            headerStr = \"(\" + \",\".join(headerList) + \")\"\n",
    "            print(\"---\" + viewNameStage + \"---\")\n",
    "        valueList = []\n",
    "        valueStr = ''\n",
    "        if index > 1:\n",
    "            valueIdx = 0\n",
    "            for valueField in row:\n",
    "                # NULL-Werte durch NULL ersetzen, sind nicht SQL kompatibel\n",
    "                if pd.notna(valueField):\n",
    "                    valueField = valueField\n",
    "                else:\n",
    "                    valueField = 'NULL'\n",
    "                # MS Access NULL in SQL NULL umwandeln\n",
    "                if valueField == '<null>' or valueField == 'NULL':\n",
    "                    valueList.append(str('NULL'))\n",
    "                # leere Datumsfelder mit NULL füllen\n",
    "                elif ( headerList[valueIdx] in fieldExceptionDic[viewNameStage] and\n",
    "                     (fieldExceptionDic[viewNameStage][headerList[valueIdx]] == \"datetime\" or\n",
    "                     fieldExceptionDic[viewNameStage][headerList[valueIdx]] == \"date\" ) and\n",
    "                     valueField == '' ):\n",
    "                    valueList.append(str('NULL'))\n",
    "                # Datumsfelder kürzen aus 23 Stellen  2022-06-14 10:16:12.570\n",
    "                elif ( headerList[valueIdx] in fieldExceptionDic[viewNameStage] and\n",
    "                     fieldExceptionDic[viewNameStage][headerList[valueIdx]] == \"datetime\" and\n",
    "                     valueField != '' ):\n",
    "                    valueList.append(\"'\" + str(valueField)[0:23] + \"'\")\n",
    "                # String Felder mit Hochkomma importieren\n",
    "                elif headerList[valueIdx] in fieldExceptionDic[viewNameStage]:\n",
    "                    valueList.append(\"'\" + str(valueField) + \"'\")\n",
    "                # leere numerische Felder mit 0 füllen\n",
    "                elif valueField == '':\n",
    "                    valueList.append(str(0))\n",
    "                # den Rest einfach importieren, wie er ist\n",
    "                else:\n",
    "                    valueList.append(str(valueField))\n",
    "                valueIdx += 1\n",
    "            valueStr = \"(\" + \",\".join(valueList) + \")\"\n",
    "        if index == 1:\n",
    "            outFileHandle.write(\"begin transaction\\ngo\\n\")\n",
    "            outFileHandle.write(\"use RiCo_PoDIuM\\n\")\n",
    "            outFileHandle.write(\"SELECT *  FROM \" + viewNameStage + \" WHERE PER_DATE_POSITION = '\" + str(perDatePosition) + \"';\\n\")\n",
    "            outFileHandle.write(\"SELECT *  FROM \" + viewNameQuery + \" WHERE PER_DATE_POSITION = '\" + str(perDatePosition) + \"';\\n\")\n",
    "            outFileHandle.write(\"insert into base.V_LOG_DLV ( PER_DATE_POSITION, STATUS_FLAG, SOURCE_OBJ, TARGET_OBJ, JOB_NAME, ERROR_DESC, MISC_DESC, TIME_STAMP)\\n\")\n",
    "            outFileHandle.write(\"values\\n\")\n",
    "            outFileHandle.write(\"( '\" + str(perDatePosition) + \"', 'S', 'Manual Insert', '\" + viewNameStage + \"', 'Manual', '', '', GETDATE())\\n\\n\")\n",
    "        if index > 1 and pd.notna(df.iat[index, 2]):\n",
    "            outFileHandle.write(\"insert into \" + viewNameStage + \" \" + headerStr + \" values \" + valueStr + \"\\n\")\n",
    "            cellCounterSheet += 1\n",
    "            cellCounterFile += 1\n",
    "    outFileHandle.write(\"\\ninsert into base.V_LOG_DLV ( PER_DATE_POSITION, STATUS_FLAG, SOURCE_OBJ, TARGET_OBJ, JOB_NAME, ERROR_DESC, MISC_DESC, TIME_STAMP )\\n\")\n",
    "    outFileHandle.write(\"values\\n\")\n",
    "    outFileHandle.write(\"( '\" + str(perDatePosition) + \"', 'E', 'Manual Insert', '\" + viewNameStage + \"', 'Manual', '', '', GETDATE())\\n\\n\")\n",
    "    outFileHandle.write(\"SELECT *  FROM \" + viewNameStage + \" WHERE PER_DATE_POSITION = '\" + str(perDatePosition) + \"';\\n\")\n",
    "    outFileHandle.write(\"SELECT *  FROM \" + viewNameQuery + \" WHERE PER_DATE_POSITION = '\" + str(perDatePosition) + \"';\\n\\n\")\n",
    "    outFileHandle.write(\"commit\\ngo\\n\")\n",
    "    outFileHandle.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08808d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
